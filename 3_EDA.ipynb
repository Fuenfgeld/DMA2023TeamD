{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fuenfgeld/DMA2023TeamD/blob/dev_branch_EDA_Prediction/3_EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTF4SC_RjLoX"
      },
      "source": [
        "# **Objective**: Exploratory Data Analysis (EDA)\n",
        "\n",
        "Exploratory data analysis is a task performed by data scientists to get familiar with the data. All the initial tasks you do to understand your data well are known as EDA.\n",
        "\n",
        "There are main components of exploring data:\n",
        "1. Understanding data/Basic Data Exploration\n",
        "2. Cleaning dataset\n",
        "3. Understanding variables\n",
        "4. Analyzing relationships between variables\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f72lAeqGmSSy"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNfOtFMuEqVt"
      },
      "source": [
        "# install the newest version,  \n",
        "# uncomment this line in first runtime, it needs to restart runtime\n",
        "!pip3 install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W6m6PYU3m9O"
      },
      "source": [
        "import ydata_profiling\n",
        "ydata_profiling.version.__version__\n",
        "# => 2.9.0 aber nun 0.0.dev0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHakU94EcNVc"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "# from datetime import datetime\n",
        "# import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas_profiling import ProfileReport\n",
        "# will make plot outputs appear and stored within the notebook.\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-042ss9IcbTC"
      },
      "source": [
        "from google.colab import drive\n",
        "# mount drive to access database\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvBpH6Wl__e5"
      },
      "source": [
        "material_path = \"/content/drive/Shareddrives/Projektarbeit DMA Gruppe D\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxgx_7_7K47Z"
      },
      "source": [
        "# list of datawarehoses\n",
        "!ls \"/content/drive/Shareddrives/Projektarbeit DMA Gruppe D/DWH_dbs\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BTwowldi9tx"
      },
      "source": [
        "\n",
        "# Loading Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzmmNYDbcnd7"
      },
      "source": [
        "# datawarehouse path\n",
        "DB_DWH_PATH = f\"{material_path}/DWH_dbs/DWH_allergy_test.db\"\n",
        "# DB_DWH_PATH = \"/content/drive/My Drive/synthea_patient_data/DWH_dbs/DWH_lung_cancer.db\"\n",
        "\n",
        "# connect to db\n",
        "dwh_conn = sqlite3.connect(DB_DWH_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3c3cyQocaXV"
      },
      "source": [
        "# list of tables in db\n",
        "if dwh_conn is not None:\n",
        "  dwh_cursor = dwh_conn.cursor()\n",
        "  dwh_cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "  print(\"List of Tables\", dwh_cursor.fetchall())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4Pk9g2SdmwO"
      },
      "source": [
        "# Read sqlite query results into a pandas DataFrame\n",
        "# demographic data\n",
        "df_patients = pd.read_sql_query(\"SELECT * FROM PATIENTS_INFO\", dwh_conn)\n",
        "# diagnoses data\n",
        "df_conditions = pd.read_sql_query(\"select * from conditions_info\", dwh_conn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBQfz7Ht4r-w"
      },
      "source": [
        "# MERGE TWO DATASETS \n",
        "df = pd.merge(df_patients, df_conditions, left_on=\"Id\", right_on=\"PATIENT\", how=\"inner\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpVlnD4otd6J"
      },
      "source": [
        "# close db connection\n",
        "# dwh_conn.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkr45V79nIYF"
      },
      "source": [
        "# Understanding Data/Basic Data Exploration\n",
        "In this step, we will perform the below operations to check what the data set comprises of. We will check the below things:\n",
        "\n",
        "* head of the dataset\n",
        "* the shape of the dataset\n",
        "* info of the dataset\n",
        "* summary of the dataset\n",
        "* (n)unique values for each variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK0LXxAAeB5i"
      },
      "source": [
        "# .head() returns the first 5 rows of my dataset. This is useful if you want to see some example values for each variable.\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu4gAaCVqhJb"
      },
      "source": [
        "# .shape returns the number of rows by the number of columns\n",
        "#size of dataset\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIO9Yf9-vhF6"
      },
      "source": [
        "# .columns returns the name of all of your columns in the dataset.\n",
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp7F79sFlNUy"
      },
      "source": [
        "# attribute type\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcAfS9u0nz1K"
      },
      "source": [
        "The described method will help to see how data has been spread for numerical values. We can clearly see the minimum value, mean values, different percentile values, and maximum values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsVt0s9FniM3"
      },
      "source": [
        "# .describe summarizes the count, mean, standard deviation, min, and max for numerical variables.\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txjvbmc_wC-C"
      },
      "source": [
        "# .nunique(axis=0) returns the number of unique values for each variable.\n",
        "df.nunique(axis=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD0OzmXLOCvG"
      },
      "source": [
        "# replacing blank values (with space) with NAN\n",
        "df = df.replace(r'^\\s*$', np.nan, regex=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iWfreIvnQSG"
      },
      "source": [
        "# profile = ProfileReport(df)\n",
        "# profile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh_OWI58q62t"
      },
      "source": [
        "#  Cleaning Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKmjieWyrHOC"
      },
      "source": [
        "### Removing Duplicate Rows\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz6AoBaOq2tK"
      },
      "source": [
        "print(\"Number of Duplicated Rows\", df.duplicated(df.columns).sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFYjWaDwm-ZW"
      },
      "source": [
        "\n",
        "# dropping duplicate values if exists and keep first one\n",
        "df.drop_duplicates(keep=\"first\",inplace=True) \n",
        "print(\"Size of dataset after removinf duplicated rows\", df.shape)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wiw6to0HqaM4"
      },
      "source": [
        "### Removing Redundant and Unnecessary Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzHbk2nMV3GR"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOI8yOuGqlLv"
      },
      "source": [
        "df = df.drop(['SSN', 'PREFIX', 'ZIP', 'DRIVERS', 'PASSPORT', 'FIRST',\n",
        "              'LAST', 'BIRTHPLACE', 'ADDRESS', 'STATE', 'COUNTRY', \n",
        "              'PATIENT', 'ENCOUNTER'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl-Fg5aIl5p7"
      },
      "source": [
        "### Handling Missing Value\n",
        "\n",
        "We can see that we have various missing values in the respective columns. There are various ways of treating your missing values in the data set. And which technique to use when is actually dependent on the type of data you are dealing with.\n",
        "\n",
        "* Drop the missing values: In this case, we drop the missing values from those variables. In case there are very few missing values you can drop those values.\n",
        "* Impute with mean value: For the numerical column, you can replace the missing values with mean values. Before replacing with mean value, it is advisable to check that the variable shouldn’t have extreme values .i.e. outliers.\n",
        "* Impute with median value: For the numerical column, you can also replace the missing values with median values. In case you have extreme values such as outliers it is advisable to use the median approach.\n",
        "* Impute with mode value: For the categorical column, you can replace the missing values with mode values i.e the frequent ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXgmTuPoXn8b"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eZYrokRlS88"
      },
      "source": [
        "# percentage of not null values in each column\n",
        "df.count()/len(df) * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pprSscZkq-WA"
      },
      "source": [
        "# number of null values in each column\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uzXBF5XpTQJ"
      },
      "source": [
        "# delete sparc columns\n",
        "df.drop(['SUFFIX', 'MAIDEN'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I6aLfamoNOy"
      },
      "source": [
        "# fill nall values with todays date\n",
        "df[\"DEATHDATE\"] = df.DEATHDATE.fillna(pd.to_datetime(\"today\"))\n",
        "df[\"STOP\"] = df.STOP.fillna(pd.to_datetime(\"today\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4rPQ4JzuDNg"
      },
      "source": [
        "# fill nall values with mode\n",
        "df['MARITAL'].fillna(df['MARITAL'].mode()[0], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te8CCISwFyDO"
      },
      "source": [
        "# convert to date\n",
        "df[\"DEATHDATE\"] = pd.to_datetime(df[\"DEATHDATE\"])\n",
        "df[\"BIRTHDATE\"] = pd.to_datetime(df[\"BIRTHDATE\"])\n",
        "df[\"START\"] = pd.to_datetime(df[\"START\"])\n",
        "df[\"STOP\"] = pd.to_datetime(df[\"STOP\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFmjwJi0wLiT"
      },
      "source": [
        "# calculate age \n",
        "df[\"AGE\"] = df.DEATHDATE.dt.year - df.BIRTHDATE.dt.year\n",
        "# df[\"DURATION_day\"] = (df.STOP.dt.year - df.START.dt.year) * 12 + (df.STOP.dt.month - df.START.dt.month)\n",
        "df[\"DURATION\"] = df.STOP.dt.to_period(\"M\").astype(int) - df.START.dt.to_period(\"M\").astype(int)\n",
        "\n",
        "df.DURATION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn5r2ukJ_Q5n"
      },
      "source": [
        "# number of null values in each column\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiePHzzw_nMe"
      },
      "source": [
        "# Univariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PufofnF6MD4"
      },
      "source": [
        "## Grouping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cje1waC5kUcN"
      },
      "source": [
        "# number of patients in procedure table\n",
        "df.groupby([\"Id\"]).size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfAq59BClryS"
      },
      "source": [
        "There are info for 133 patients in table.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PajN4ImhlGLO"
      },
      "source": [
        "df.groupby([\"Id\", \"CODE\"]).size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZJrKDhmlRzu"
      },
      "source": [
        "For some patients, there are more than one diagnose."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTPB7aU5sAaB"
      },
      "source": [
        "## Histogram\n",
        "\n",
        "if you only wanted to explore a single variable by itself? This is when histograms come into play.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4x0mMw_YO7q"
      },
      "source": [
        "df['AGE'].plot(kind='hist', bins=20, figsize=(12,6), facecolor='grey',edgecolor='black')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcW0gCqhBe9C"
      },
      "source": [
        "# # binning age column and remove age attribute\n",
        "# bins = [i for i in range(df.AGE.min(), df.AGE.max(), 5)]\n",
        "# df['AGE_BINS'] = pd.cut(x=df['AGE'], bins=bins)\n",
        "\n",
        "# df.drop([\"AGE\"], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q6K_u77-9Gk"
      },
      "source": [
        "\n",
        "## Boxplot and Removing Outlier\n",
        "\n",
        "We can discover outliers with visualization tools:\n",
        "* Box plot\n",
        "* Scatter plot\n",
        "* Z-Score\n",
        "* IQR Score\n",
        "\n",
        "For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HQHBfE3nA8t"
      },
      "source": [
        "sns.boxplot(x=df[\"DURATION\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t93zATxfnhaE"
      },
      "source": [
        "df = df[df[\"DURATION\"]<1200]\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko_qIt9eCOD8"
      },
      "source": [
        "## Countplot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9sUPtstznBw"
      },
      "source": [
        "# distribution of GENDER attribute\n",
        "sns.countplot(x=\"variable\", hue= \"value\", data=pd.melt(df[[\"GENDER\"]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2P0XXybl7jh"
      },
      "source": [
        "# distribution of Marital attribute\n",
        "sns.countplot(x=\"variable\", hue= \"value\", data=pd.melt(df[[\"MARITAL\"]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OyAU_FAmD_-"
      },
      "source": [
        "# distribution of RACE attribute\n",
        "sns.countplot(x=\"variable\", hue= \"value\", data=pd.melt(df[[\"RACE\"]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVkAbjaYpC0_"
      },
      "source": [
        "# distribution of RACE attribute\n",
        "sns.countplot(x=\"variable\", hue= \"value\", data=pd.melt(df[[\"ETHNICITY\"]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWr90BL6oVkm"
      },
      "source": [
        "# convert categorical variable to numerical by replacing\n",
        "df.GENDER.replace(['M', 'F'], [0, 1], inplace=True)\n",
        "df.MARITAL.replace(['M', 'S'], [0, 1], inplace=True)\n",
        "df.RACE.replace([\"white\", \"black\", \"asian\"], [1, 2, 3], inplace=True)\n",
        "df.ETHNICITY.replace([\"nonhispanic\", \"hispanic\"], [0, 1], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iDAA2t2ru1m"
      },
      "source": [
        "#  Multivariate Analysis: Analyzing Relationships Between Variables\n",
        "\n",
        "Correlation matrices and scatterplots are useful for exploring the relationship between two variables.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH2I4GRwr0U5"
      },
      "source": [
        "### Correlation Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbFlznbxxZMg"
      },
      "source": [
        "# list of columns\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AZcOnNiUP54"
      },
      "source": [
        "# Generating the correlating matrix\n",
        "corr = df.corr()\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "# Generating the correlation heat-map\n",
        "sns.heatmap(corr, annot=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDGVtnhs8qXu"
      },
      "source": [
        "# df subset contains numerical variables\n",
        "numdf = df.select_dtypes(include=np.number)\n",
        "# df subset contains categorical variables\n",
        "catdf = df.select_dtypes(exclude=np.number)\n",
        "numdf.shape, catdf.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4ZIvxZRvETQ"
      },
      "source": [
        "# select feature with correlation less than a threshold\n",
        "columns = np.full((corr.shape[0],), True, dtype=bool)\n",
        "for i in range(corr.shape[0]):\n",
        "    for j in range(i+1, corr.shape[0]):\n",
        "        if corr.iloc[i,j] >= 0.7:\n",
        "            if columns[j]:\n",
        "                columns[j] = False\n",
        "\n",
        "selected_columns = numdf.columns[columns]\n",
        "selected_columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u69s4i1nuDa"
      },
      "source": [
        "* It is obvious correlation between GENDER and SCT_CODE_PROCEDURE < correlation between SCT_CODE_PROCEDURE and AGE.\n",
        "\n",
        "*   AGE and GENDER are correlated.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwHh9ya9r74M"
      },
      "source": [
        "### Scatterplot\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjBgjghYW5QP"
      },
      "source": [
        "df.plot(kind='scatter', y='HEALTHCARE_EXPENSES', x='AGE')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsSTvW2I48CG"
      },
      "source": [
        "df = df[(df[\"AGE\"]<100)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK0bJ2F6yaH2"
      },
      "source": [
        "df.plot(kind='scatter', y='DURATION', x='AGE')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy9ZYDS7yqxX"
      },
      "source": [
        "df.plot(kind='scatter', y='HEALTHCARE_EXPENSES', x='AGE')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLeSLqDq91wF"
      },
      "source": [
        "df.plot(kind='scatter', y='AGE', x='RACE')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmAuLO3dXr66"
      },
      "source": [
        "df.plot(kind='scatter', y='HEALTHCARE_EXPENSES', x='RACE')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1SAcT7mVA_4"
      },
      "source": [
        "df.plot(kind='scatter', x='MARITAL', y='AGE')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4iDkts1XF2n"
      },
      "source": [
        "df.plot(kind='scatter', x='HEALTHCARE_EXPENSES', y='GENDER')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cZ1AWHwX8RQ"
      },
      "source": [
        "# sns.pairplot(df_selected)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2wiS0LcsOW7"
      },
      "source": [
        "### PCA\n",
        "Principal components are the key to PCA; It is used on two use-case:\n",
        "* Data visualization\n",
        "* Speeding machine learning algorithms\n",
        "\n",
        "PCA is effected by scale so you need to scale the features in your data before applying PCA. Use StandardScaler to help you standardize the dataset’s features onto unit scale (mean = 0 and variance = 1) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQL2pUfc9Z5J"
      },
      "source": [
        "# select some columns\n",
        "df_selected = df[[ \"MARITAL\", \"RACE\", \"ETHNICITY\", \"GENDER\", \"AGE\", 'DURATION', 'CODE', \"HEALTHCARE_EXPENSES\", 'HEALTHCARE_COVERAGE']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYmVxE39IeOB"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "features = ['MARITAL', 'RACE', 'ETHNICITY', 'GENDER', 'AGE', 'DURATION', 'HEALTHCARE_EXPENSES', 'HEALTHCARE_COVERAGE']\n",
        "# # Separating out the features\n",
        "x = df_selected.loc[:, features].values\n",
        "# # Separating out the target\n",
        "y = df_selected.loc[:,['CODE']].values\n",
        "# # Standardizing the features\n",
        "x = StandardScaler().fit_transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z337Io7NAhLj"
      },
      "source": [
        "# check normalization\n",
        "x.shape, np.mean(x), np.std(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6fJlKk94gK5"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "principalComponents = pca.fit_transform(x)\n",
        "principalDf = pd.DataFrame(data = principalComponents\n",
        "             , columns = ['principal component 1', 'principal component 2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Evb17CCJ7zG"
      },
      "source": [
        "finalDf = pd.concat([principalDf, df_selected[['CODE']]], axis = 1)\n",
        "finalDf.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM9GzLSRCBRN"
      },
      "source": [
        "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cYf_1MzCKQX"
      },
      "source": [
        "From the above output, you can observe that the principal component 1 holds 31.6% of the information while the principal component 2 holds only 18% of the information. Also, the other point to note is that while projecting  data to a two-dimensional data, 50% information was lost."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riO5scfTC6K-"
      },
      "source": [
        "df_selected.CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0KNQ7wZJhFy"
      },
      "source": [
        "fig = plt.figure(figsize = (8,8))\n",
        "ax = fig.add_subplot(1,1,1) \n",
        "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
        "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
        "ax.set_title('2 component PCA', fontsize = 20)\n",
        "targets = ['MARITAL', 'RACE', 'ETHNICITY''GENDER', 'AGE']\n",
        "targets = [19169002,162864005, 197927001, 10509002, 444814009]\n",
        "colors = ['r', 'g', 'b', 'g', 'c']\n",
        "for target, color in zip(targets,colors):\n",
        "    indicesToKeep = finalDf['CODE'] == target\n",
        "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
        "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
        "               , c = color\n",
        "               , s = 50)\n",
        "ax.legend(targets)\n",
        "ax.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI86n5nOBEUq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8iykEnFwgGQ"
      },
      "source": [
        "# Links\n",
        "https://chrisalbon.com/python/basics/strings_to_datetime/\n",
        "\n",
        "https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
        "\n",
        " EDA: \n",
        " \n",
        " https://towardsdatascience.com/a-gentle-introduction-to-exploratory-data-analysis-f11d843b8184\n",
        "\n",
        " https://towardsdatascience.com/an-extensive-guide-to-exploratory-data-analysis-ddd99a03199e\n",
        "\n",
        " https://www.analyticssteps.com/blogs/how-do-exploratory-data-analysis-building-machine-learning-models\n",
        "\n",
        "\n",
        " https://www.analyticsvidhya.com/blog/2020/08/exploratory-data-analysiseda-from-scratch-in-python/\n",
        "\n",
        "\n",
        " PCA\n",
        "\n",
        " https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfhyCRnILurq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}